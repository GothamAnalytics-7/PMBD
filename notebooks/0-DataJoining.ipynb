{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986e2f01",
   "metadata": {},
   "source": [
    "<img src=\"https://www.iscte-iul.pt/assets/images/logo_iscte_detailed.svg\" style=\"width: 450px;margin-top:30px;\" align =\"center\">\n",
    "\n",
    "<div style= \"font-size: 40px;  margin-top:40px; font-weight:bold; font-family: 'Avenir Next LT Pro', sans-serif;\"><center>Data Joining: <strong>E-Commerce</strong></center></div>\n",
    "<div style= \"font-size: 35px; font-weight:bold; font-family: 'Avenir Next LT Pro', sans-serif;\"><center>Merging the 2 csv files to a unique parquet</center></div>\n",
    "\n",
    "<div style= \"font-size: 27px;font-weight:bold;line-height: 1.1; margin-top:40px; font-family: 'Avenir Next LT Pro', sans-serif;\"><center>Processamento e Modelação de Big Data 2024/2025</center></div> <br>\n",
    "\n",
    "   <div style= \"font-size: 20px;font-weight:bold; font-family: 'Avenir Next LT Pro', sans-serif;\"><center> Grupo 7:</center></div>\n",
    "   <div><center> Diogo Freitas | 104841 </center></div>\n",
    "   <div><center> João Francisco Botas | 104782 </center></div>\n",
    "   <div><center> Miguel Gonçalves | 105944 </center></div>\n",
    "   <div><center> Ricardo Galvão | 105285 </center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1bfff",
   "metadata": {},
   "source": [
    "--- \n",
    "## Spark Session\n",
    "\n",
    "Iniciar a sessão do Spark com o nome de `Projeto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f49763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, LongType, DoubleType, TimestampType\n",
    ")\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PMBD\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65aebb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext._jsc.sc().isStopped())  # False -> tudo bem; True -> Spark está desligado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6c38f",
   "metadata": {},
   "source": [
    "---\n",
    "## Read Data\n",
    "\n",
    "Primeiro vamos definir o schema ao ler os dados para ser mais eficiente a leitura.\n",
    "\n",
    "NOTA: **Ajustar a pasta de `data` consoante o caminho**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f16c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files on data folder\n",
    "data_dir = \"../data/\"\n",
    "dataRaw_dir = data_dir + \"raw/\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"event_time\", TimestampType(), True),\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"product_id\", LongType(), True),\n",
    "    StructField(\"category_id\", LongType(), True),\n",
    "    StructField(\"category_code\", StringType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"user_id\", LongType(), True),\n",
    "    StructField(\"user_session\", StringType(), True)\n",
    "])\n",
    "\n",
    "# ec_total = spark.read.csv(data_dir, header=True, schema=schema)\n",
    "\n",
    "ec_oct = spark.read \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .csv(dataRaw_dir + \"2019-Oct.csv\", header=True, schema=schema)\n",
    "\n",
    "ec_nov = spark.read \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .csv(dataRaw_dir + \"2019-Nov.csv\", header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d90fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "|         event_time|event_type|product_id|        category_id|       category_code| brand| price|  user_id|        user_session|\n",
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "|2019-11-01 00:00:00|      view|   1003461|2053013555631882655|electronics.smart...|xiaomi|489.07|520088904|4d3b30da-a5e4-49d...|\n",
      "|2019-11-01 00:00:00|      view|   5000088|2053013566100866035|appliances.sewing...|janome|293.65|530496790|8e5f4f83-366c-4f7...|\n",
      "|2019-11-01 00:00:01|      view|  17302664|2053013553853497655|                NULL| creed| 28.31|561587266|755422e7-9040-477...|\n",
      "|2019-11-01 00:00:01|      view|   3601530|2053013563810775923|appliances.kitche...|    lg|712.87|518085591|3bfb58cd-7892-48c...|\n",
      "|2019-11-01 00:00:01|      view|   1004775|2053013555631882655|electronics.smart...|xiaomi|183.27|558856683|313628f1-68b8-460...|\n",
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ec_nov.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea3dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in October 2019 file: 42448764\n",
      "Number of rows in November 2019 file: 67501979\n"
     ]
    }
   ],
   "source": [
    "# count rows\n",
    "print(f\"Number of rows in October 2019 file: {ec_oct.count()}\")\n",
    "print(f\"Number of rows in November 2019 file: {ec_nov.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23732e20",
   "metadata": {},
   "source": [
    "- Number of rows in October 2019 file: 42448764\n",
    "- Number of rows in November 2019 file: 67501979"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616a728",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Joining\n",
    "\n",
    "Juntar os dados dos dois ficheiros e depois escrever num parquet para ser utilizado mais para a frente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd85fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in total dataset file: 109950743\n"
     ]
    }
   ],
   "source": [
    "# merge the two datasets\n",
    "ec_total = ec_oct.union(ec_nov)\n",
    "print(f\"Number of rows in total dataset file: {ec_total.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d8b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O diretório já existe. Não foi sobrescrito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_path = dataRaw_dir + \"ec_total.parquet\"\n",
    "if not os.path.exists(output_path):\n",
    "    ec_total.write.format(\"parquet\").mode(\"overwrite\").save(output_path)\n",
    "else:\n",
    "    print(\"O diretório já existe. Não foi sobrescrito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2099f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73fe6e",
   "metadata": {},
   "source": [
    "---\n",
    "Ler o parquet para ver se está tudo bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4a2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "|         event_time|event_type|product_id|        category_id|       category_code|        brand| price|  user_id|        user_session|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "|2019-11-17 08:43:00|      view|   1005253|2053013555631882655|electronics.smart...|       xiaomi|288.04|516404307|a383cb03-2673-446...|\n",
      "|2019-11-17 08:43:01|      view|  60000003|2162513074060264222|                NULL|geoffanderson|  44.4|515817144|505cf403-f7ce-4ab...|\n",
      "|2019-11-17 08:43:01|      view|   4700388|2053013560899928785|auto.accessories....|    prestigio| 32.18|572492652|4879a14c-58b3-43a...|\n",
      "|2019-11-17 08:43:01|      cart|  28718385|2053013565228450757|       apparel.shoes|       rieker|103.99|518296473|8af4a493-9188-43a...|\n",
      "|2019-11-17 08:43:01|      cart|  26500142|2053013563550729061|                NULL|      lucente|234.76|514929163|f77c9416-abd5-47a...|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read parquet file and select 5% of the data\n",
    "ec_total = spark.read.parquet(dataRaw_dir + \"ec_total.parquet\")\n",
    "# TODO: talvez ajustar porque a ordem pode ser aleatoria nos 5%\n",
    "ec_5p = ec_total.sample(fraction=0.05, seed=42)\n",
    "ec_5p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f86a7073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the 5% sample: 5495486\n"
     ]
    }
   ],
   "source": [
    "# count rows\n",
    "print(f\"Number of rows in the 5% sample: {ec_5p.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9805b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the parquet file: 109950743\n",
      "Number of rows of each : 109950743\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in the parquet file: {ec_total.count()}\")\n",
    "print(f\"Number of rows of each : {42448764 + 67501979}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e768ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "|         event_time|event_type|product_id|        category_id|       category_code|        brand| price|  user_id|        user_session|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "|2019-11-17 08:43:00|      view|   1005253|2053013555631882655|electronics.smart...|       xiaomi|288.04|516404307|a383cb03-2673-446...|\n",
      "|2019-11-17 08:43:01|      view|  60000003|2162513074060264222|                NULL|geoffanderson|  44.4|515817144|505cf403-f7ce-4ab...|\n",
      "|2019-11-17 08:43:01|      view|   4700388|2053013560899928785|auto.accessories....|    prestigio| 32.18|572492652|4879a14c-58b3-43a...|\n",
      "|2019-11-17 08:43:01|      cart|  28718385|2053013565228450757|       apparel.shoes|       rieker|103.99|518296473|8af4a493-9188-43a...|\n",
      "|2019-11-17 08:43:01|      cart|  26500142|2053013563550729061|                NULL|      lucente|234.76|514929163|f77c9416-abd5-47a...|\n",
      "|2019-11-17 08:43:01|      view|  19100147|2053013556227473861|construction.tool...|         NULL|239.39|560431625|5aca4f90-8977-433...|\n",
      "|2019-11-17 08:43:01|      view|   2402910|2053013563743667055|appliances.kitche...|   electrolux|211.05|568032756|785aa2ec-9f4e-44a...|\n",
      "|2019-11-17 08:43:02|      view|   1004259|2053013555631882655|electronics.smart...|        apple|824.94|518294516|15c91f85-7961-46f...|\n",
      "|2019-11-17 08:43:02|      view|  13104185|2053013553526341921|                NULL|         NULL|310.43|514989268|7993b636-0054-492...|\n",
      "|2019-11-17 08:43:03|      view|  15800012|2053013560144954031|                NULL|        bosch| 83.81|521005231|c155228f-8e1d-4e0...|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------------+------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 10 rows\n",
    "ec_5p.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b5a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ec_5p.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc90cd",
   "metadata": {},
   "source": [
    "Produtos com mais de 2 categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "956191c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>num_categorias</th>\n",
       "      <th>lista_category_id</th>\n",
       "      <th>lista_category_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [product_id, num_categorias, lista_category_id, lista_category_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, collect_list, collect_set\n",
    "\n",
    "# 1. Filtrar produtos com mais de 2 categorias distintas\n",
    "produtos_com_mais_de_2_cat = ec_total.groupBy(\"product_id\") \\\n",
    "    .agg(\n",
    "        countDistinct(\"category_id\").alias(\"num_categorias\"),\n",
    "        collect_set(\"category_id\").alias(\"lista_category_id\"),\n",
    "        collect_set(\"category_code\").alias(\"lista_category_code\")\n",
    "    ) \\\n",
    "    .filter(\"num_categorias > 2\") \\\n",
    "    .orderBy(\"num_categorias\", ascending=False)\n",
    "\n",
    "# 2. Converter para pandas para visualização\n",
    "produtos_com_mais_de_2_cat.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
